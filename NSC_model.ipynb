{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSC_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoonRiyadh/Neural-Symbolic-Computing/blob/master/NSC_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE3T4F2jFQS4",
        "colab_type": "text"
      },
      "source": [
        "The cell below only needs to be run on google colab\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBs61tjBMfMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torchtext==0.7\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYvAJG9kFWws",
        "colab_type": "text"
      },
      "source": [
        "Below should be the path to the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUbRx1doFVv7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# directory to data\n",
        "dirname = \"/content/drive/My Drive/Colab Notebooks/NSC_Project/Project.zip (Unzipped Files)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nGIPtnCFeU7",
        "colab_type": "text"
      },
      "source": [
        "imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqsIfDu1dq_J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7eaa0047-2d69-44fd-91ad-bc1758da91b3"
      },
      "source": [
        "# imports\n",
        "import torch \n",
        "import torchtext\n",
        "import os\n",
        "from nltk import regexp_tokenize\n",
        "from torch import nn, functional\n",
        "\n",
        "\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kppB3RX9AiS8",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXGYAwQIyAPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SAMPLE_LINES = 4\n",
        "\n",
        "# The torchtext.data.Dataset class is not needed but is useful\n",
        "class CustomDataset(torchtext.data.Dataset):\n",
        "    def __init__(self, path, fields, **kwargs):\n",
        "        \"\"\"\n",
        "        paths:\n",
        "            path to data\n",
        "        fields:\n",
        "            tuple of Field objects (see torchtext.data.Field)\n",
        "        \"\"\"\n",
        "\n",
        "        if not isinstance(fields[0], (tuple, list)):\n",
        "            fields = [('input', fields[0]), ('output', fields[1])]\n",
        "\n",
        "        with open(path) as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        if len(lines) % 4 != 0:\n",
        "            raise Exception(f\":(, incomplete sample in {path}\")\n",
        "        \n",
        "        \n",
        "        examples = []\n",
        "        for i in range(0, len(lines), SAMPLE_LINES):\n",
        "            y = list(lines[i + SAMPLE_LINES - 1].strip())\n",
        "            x = \"\".join(lines[i:i+SAMPLE_LINES - 1])\n",
        "\n",
        "            examples.append(torchtext.data.Example.fromlist(\n",
        "                        [x, y], fields))\n",
        "        \n",
        "        super().__init__(examples, fields, **kwargs)\n",
        "\n",
        "    @classmethod\n",
        "    def create_datasets(cls, train, test, validation, fields, **kwargs):\n",
        "        \"\"\"\n",
        "        train:\n",
        "            path to train data\n",
        "        test:\n",
        "            path to test data\n",
        "        validation:\n",
        "            path to validation data\n",
        "        fields:\n",
        "            tuple of Field objects (see torchtext.data.Field)\n",
        "        \"\"\"\n",
        "        train_set = cls(path=train, fields=fields, **kwargs)\n",
        "        test_set = cls(path=test, fields=fields, **kwargs)\n",
        "        validation_set = cls(path=validation, fields=fields, **kwargs)\n",
        "\n",
        "\n",
        "        return train_set, test_set, validation_set "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8spk4uTuS1QK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fdfd46d0-94ad-462d-bb90-ebdfdcec2064"
      },
      "source": [
        "def custom_tokenizer(s):\n",
        "    ret = regexp_tokenize(s, r'(var|=|[a-z]+\\d*|\\d|[+-])')\n",
        "    return ret\n",
        "\n",
        "INPUT = torchtext.data.Field(tokenize = custom_tokenizer,\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "OUTPUT = torchtext.data.Field(tokenize = custom_tokenizer,\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "# get datasets\n",
        "train_data, test_data, validation_data = CustomDataset.create_datasets(\n",
        "    *(os.path.join(dirname, f\"{name}_Data.txt\") for name in \"Training Test Validation\".split()),\n",
        "    fields=(INPUT, OUTPUT)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKaIJ69zS4op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create vocabs\n",
        "INPUT.build_vocab(train_data)\n",
        "OUTPUT.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bPlD81-e5WR",
        "colab_type": "text"
      },
      "source": [
        "## Iterators/Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIPcySD6arpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "f07c71d1-a20e-4eac-dc3f-3edee0dfc536"
      },
      "source": [
        "# get iters\n",
        "train_iterator, valid_iterator, test_iterator = torchtext.data.BucketIterator.splits(\n",
        "    (train_data, validation_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device,\n",
        "    sort_key=lambda x: len(x.input + x.output))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvEaGbkRe-Pd",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjpO-Kjpb3pB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, embedding_dim, in_vocab_size, out_vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding_in = nn.Embedding(in_vocab_size, embedding_dim).to(device)\n",
        "        self.embedding_out = nn.Embedding(out_vocab_size, embedding_dim).to(device)\n",
        "        self.transformer = nn.Transformer(d_model=embedding_dim).to(device)\n",
        "    \n",
        "    def forward(self, src, tgt):\n",
        "        in_embeds = self.embedding_in(src)\n",
        "        out_embeds = self.embedding_out(tgt)\n",
        "        return self.transformer(in_embeds, out_embeds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTQj0_BXH4dD",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKWWGp96d_zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Seq2Seq(128, in_vocab_size=len(INPUT.vocab.stoi), out_vocab_size=len(OUTPUT.vocab.stoi))\n",
        "\n",
        "# ignore padding (we removed but just in case)\n",
        "PAD_IDX = OUTPUT.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsbdoHslsOWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX4GTrhEi-wd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "0860062f-5367-4de8-8e58-a80fd546e1fd"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def train(model,\n",
        "          iterator,\n",
        "          optimizer,\n",
        "          criterion,\n",
        "          clip):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.input\n",
        "        trg = batch.output\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model,\n",
        "             iterator,\n",
        "             criterion):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.input\n",
        "            trg = batch.output\n",
        "\n",
        "            output = model(src, trg) \n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time,\n",
        "               end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 5\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "losses = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    losses.append((train_loss, valid_loss))\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 6m 34s\n",
            "\tTrain Loss: 0.079\n",
            "\t Val. Loss: 0.000\n",
            "Epoch: 02 | Time: 6m 33s\n",
            "\tTrain Loss: 0.001\n",
            "\t Val. Loss: 0.000\n",
            "Epoch: 03 | Time: 6m 33s\n",
            "\tTrain Loss: 0.000\n",
            "\t Val. Loss: 0.000\n",
            "Epoch: 04 | Time: 6m 33s\n",
            "\tTrain Loss: 0.000\n",
            "\t Val. Loss: 0.000\n",
            "Epoch: 05 | Time: 6m 34s\n",
            "\tTrain Loss: 0.000\n",
            "\t Val. Loss: 0.000\n",
            "| Test Loss: 0.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4tvekIPjEFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save\n",
        "torch.save(model.state_dict(), os.path.join(dirname, \"model_params.pyt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mvUcV1mfs8q",
        "colab_type": "text"
      },
      "source": [
        "## Loss progression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "parU2VHHcRsh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "3d9abc87-33e0-4b34-8245-54438cbc8d94"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.offline import iplot\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(losses, columns=['training_loss', 'validation_loss'])\n",
        "\n",
        "training_trace = go.Scatter(mode=\"lines+markers\",\n",
        "                  x = df.index,\n",
        "                  y = df.training_loss,\n",
        "                  name = \"training loss\")\n",
        "validation_trace = go.Scatter(mode=\"lines+markers\",\n",
        "                        x = df.index,\n",
        "                        y = df.validation_loss,\n",
        "                        name = \"validation loss\")\n",
        "\n",
        "data = [training_trace, validation_trace]\n",
        "layout = go.Layout(\n",
        "    title=\"Loss progression\",\n",
        "    yaxis=dict(\n",
        "        title=\"loss\"\n",
        "    ),\n",
        "    xaxis=dict(\n",
        "        title=\"epoch #\"\n",
        "    )\n",
        ")\n",
        "\n",
        "fig = go.Figure(data=data, layout=layout)\n",
        "fig.update_xaxes(dtick=1)\n",
        "iplot(fig)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"ea8da2b8-a3a0-4631-8fdf-b5332748ec29\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"ea8da2b8-a3a0-4631-8fdf-b5332748ec29\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'ea8da2b8-a3a0-4631-8fdf-b5332748ec29',\n",
              "                        [{\"mode\": \"lines+markers\", \"name\": \"training loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.07905710699987598, 0.0007236574676306918, 0.0004574058012617752, 0.0003469770633755252, 0.00028784777072025464]}, {\"mode\": \"lines+markers\", \"name\": \"validation loss\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4], \"y\": [0.00026244134236516576, 0.00016056982990320952, 0.00012415883278444736, 0.00010471565527324875, 9.312285430980381e-05]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Loss progression\"}, \"xaxis\": {\"dtick\": 1, \"title\": {\"text\": \"epoch #\"}}, \"yaxis\": {\"title\": {\"text\": \"loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ea8da2b8-a3a0-4631-8fdf-b5332748ec29');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DUFqhWb3jlN",
        "colab_type": "text"
      },
      "source": [
        "# Test\n",
        "Use the directly following cell to load the model and to test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiLITb42qbzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set to True to load model\n",
        "LOAD = True\n",
        "# set to file containing parameters\n",
        "PATH_TO_PARAMETERS = os.path.join(dirname, \"model_params.pyt\")\n",
        "\n",
        "def download_params():\n",
        "    import requests\n",
        "\n",
        "    url = \"https://dl.dropboxusercontent.com/s/vgdfeopm1ybmwvx/model_params.pyt?dl=0\"\n",
        "\n",
        "    content = requests.get(url).content\n",
        "\n",
        "    with open(PATH_TO_PARAMETERS, \"wb\") as file:\n",
        "        file.write(content)\n",
        "\n",
        "if LOAD:\n",
        "    model = Seq2Seq(128, 20, 15)\n",
        "    if not os.path.exists(PATH_TO_PARAMETERS):\n",
        "        download_params()\n",
        "    model.load_state_dict(torch.load(PATH_TO_PARAMETERS))\n",
        "    model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW8BuW-Wz8Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def output_to_sentence(output):\n",
        "    return ''.join((OUTPUT.vocab.itos[torch.argmax(n).item()] for n in output))\n",
        "\n",
        "def test(x, y, add, complete=False):\n",
        "    \"\"\"\n",
        "    x,y : int\n",
        "        numbers\n",
        "    add : boolean\n",
        "        whether to add or to subtract\n",
        "    complete : boolean\n",
        "        give out complete sentence (with sos and eos tokens)\n",
        "    \"\"\"\n",
        "    if add:\n",
        "        res = x+y\n",
        "        op = '+'\n",
        "    else:\n",
        "        res = x-y\n",
        "        op = '-'\n",
        "    \n",
        "    input_str =  f\"var x = {x}\\nvar y = {y}\\nx{op}y\\n\"\n",
        "    output_str = f\"{res}\\n\"\n",
        "\n",
        "    print(res)\n",
        "\n",
        "    example = torchtext.data.Example.fromlist([input_str, output_str], [('input', INPUT), ('output', OUTPUT)])\n",
        "\n",
        "    b = torchtext.data.Batch((example,), test_data, device)\n",
        "\n",
        "    model.eval()\n",
        "    output = model(b.input, b.output)\n",
        "\n",
        "    # reorganize and cutoff sos\n",
        "    output = output[0 if complete else 1:].view(-1, output.shape[-1])\n",
        "    y = b.output[0 if complete else 1:].view(-1)\n",
        "\n",
        "    # cutoff eos (potentially)\n",
        "    output = output[:-1] if not complete else output\n",
        "    y = y[:-1] if not complete else y\n",
        "\n",
        "    exp = ''.join((OUTPUT.vocab.itos[x] for x in y))\n",
        "    got = output_to_sentence(output)\n",
        "\n",
        "    # set green if same else red\n",
        "    OKGREEN = '\\033[92m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "\n",
        "    color = OKGREEN if exp == got else FAIL\n",
        "\n",
        "    print(\"Expected:\", exp)\n",
        "    print(\"Got:    \", color, got, ENDC)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngDW7AabuOMr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "b77a9339-200e-4ed3-8cf2-36f601a7dc03"
      },
      "source": [
        "test(95012, 100, add=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94912\n",
            "Expected: 94912\n",
            "Got:     \u001b[92m 94912 \u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeHub06FQXP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}